# Thin pipeline configuration (100 problems, ~570 QA examples)
# Purpose: Validate the full E2E flow before scaling to 25k problems

codi:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  ckpt_path: "checkpoints/codi-llama"
  num_latent: 6
  inf_latent_iterations: 6
  use_prj: true
  prj_dim: 2048
  remove_eos: true
  use_lora: true
  lora_r: 128
  lora_alpha: 32
  greedy: true

extraction:
  num_problems: 100
  dataset_name: "zen-E/GSM8k-Aug"
  dataset_split: "train"
  layers: [4, 8, 12]
  extract_post_projection: true
  decode_top_k: 5
  batch_size: 1
  output_dir: "data/activations_thin"
  seed: 42

qa:
  examples_per_category:
    cat1_intermediate_result: 100
    cat2_operation_classification: 150
    cat3_full_reasoning: 50
    cat4_problem_properties: 100
    cat5_context_prediction: 100
    cat6_thought_informativeness: 70
  num_paraphrases: 12
  train_val_split: 0.80
  output_dir: "data/qa_datasets_thin"
  seed: 42

ao_training:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  hook_onto_layer: 1
  lora_r: 64
  lora_alpha: 128
  lora_dropout: 0.05
  num_epochs: 3
  lr: 1.0e-5
  train_batch_size: 4
  eval_batch_size: 8
  gradient_accumulation_steps: 4
  warmup_ratio: 0.1
  bf16: true
  steering_coefficient: 1.0
  eval_steps: 50
  save_steps: 100
  logging_steps: 10
  output_dir: "checkpoints/ao_thin"
  wandb_project: "codi-ao-thin"
  train_data_path: "data/qa_datasets_thin/train.pt"
  eval_data_path: "data/qa_datasets_thin/eval.pt"
  seed: 42

eval:
  ao_checkpoint_path: "checkpoints/ao_thin/final"
  eval_data_path: "data/qa_datasets_thin/eval.pt"
  output_dir: "results/thin"
  eval_batch_size: 8
  max_new_tokens: 64
